{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56tfDxbWVq9b"
   },
   "source": [
    "# **Scraping a Site**\n",
    "### Extract links for all countries from the website https://starbucksmenuprices.com/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTkEIC3CWIvR"
   },
   "source": [
    "## **Step 1: Install Necessary Libraries**\n",
    "Python libraries extend the functionality of Python. Here, we need:\n",
    "*   requests: To fetch the webpage.\n",
    "*   BeautifulSoup (from bs4): To parse and extract data from the HTML.\n",
    "### **Command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf-x5vXBWJLM"
   },
   "outputs": [],
   "source": [
    "# pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrNyesRYWegF"
   },
   "source": [
    "## **Step 2: Import Libraries**\n",
    "We start the Python script by importing the libraries we installed. Think of this as unlocking tools we’ll need for our task.\n",
    "*   **import requests**: Enables us to send a request to a webpage.\n",
    "*   **from bs4 import BeautifulSoup**: Allows us to use BeautifulSoup for extracting data.\n",
    "### **Command:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WR3ARXxfWZY_"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import requests  # For fetching the webpage\n",
    "from bs4 import BeautifulSoup  # For parsing the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJU96afEWt9W"
   },
   "source": [
    "## **Step 3: Fetch the Webpage Content**\n",
    "Webpages are made of HTML (a markup language for displaying content). To analyze it, we first need to download the HTML using Python.\n",
    "*  **url = '...'**: This variable stores the URL of the website we want to scrape.\n",
    "*  **requests.get(url)**: Sends a request to the server to get the webpage's content.\n",
    "*   **response.status_code**: Checks the server's response. A code of 200 means the request was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8UNA0YZXAxP",
    "outputId": "4b0c701e-a0bc-4835-8b72-9e3478a20b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage!\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage to scrape\n",
    "url = 'https://starbucksmenuprices.com/'\n",
    "\n",
    "# Send a request to the server\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the webpage!\")\n",
    "else:\n",
    "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awzb8luHdFja"
   },
   "source": [
    "**Common Status Codes:**\n",
    "*   200 OK: The request was successful.\n",
    "*   201 Created: The request has been fulfilled, resulting in the creation of a new resource.\n",
    "*   204 No Content: The server successfully processed the request, but is not returning any content.\n",
    "*   301 Moved Permanently: The requested resource has been permanently moved to a new location.\n",
    "*   302 Found (Temporary Redirect): The requested resource has been temporarily moved to a new location.\n",
    "*   400 Bad Request: The server cannot or will not process the request due to an apparent client error.\n",
    "*   401 Unauthorized: The request requires user authentication.\n",
    "*   403 Forbidden: The server understood the request, but refuses to fulfill it.\n",
    "*   404 Not Found: The server cannot find the requested resource.\n",
    "*   500 Internal Server Error: The server encountered an unexpected condition that prevented it from fulfilling the request.\n",
    "*   503 Service Unavailable: The server is currently unable to handle the request due to a temporary overload or maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Heh1vR1FXUqZ"
   },
   "source": [
    "## **Step 4: Parse the HTML Content**\n",
    "Now that we have the HTML, we need to make it readable for Python using BeautifulSoup.\n",
    "*  **response.text**: The raw HTML text of the webpage.\n",
    "*   **BeautifulSoup(..., 'html.parser')**: Converts the raw HTML into a structured format that Python can easily work with.\n",
    "*   **soup.prettify()**: Prints the HTML in an indented format, making it easier to inspect.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-U2hL-IFX0Jg"
   },
   "outputs": [],
   "source": [
    "# Parse the webpage content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Print the HTML content to understand its structure\n",
    "# print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IdlMyIyX4WT"
   },
   "source": [
    "## **Step 5: Locate the Links**\n",
    "To extract links, inspect the website’s structure using your browser’s developer tools (right-click > \"Inspect\").\n",
    "\n",
    "*   Identify the < a > tags (used for links) within the < ul > list elements.\n",
    "*  **soup.find_all('ul')**: Finds all < ul > (unordered list) elements on the page.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPb3iMD1X0tD",
    "outputId": "5e92e3b6-b018-4ecf-a034-87f0e2d48bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"sub-menu\">\n",
      "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-32\" id=\"menu-item-32\"><a href=\"https://starbucksmenuprices.com/starbucks-au-prices/\">Australia</a></li>\n",
      "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42\" id=\"menu-item-42\"><a href=\"https://starbucksmenuprices.com/starbucks-brasil-precos/\">Brasil</a></li>\n",
      "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-70\" id=\"menu-item-70\"><a href=\"https://starbucksmenuprices.com/starbucks-%d1%86%d0%b5%d0%bd%d0%b8/\">Bulgaria</a></li>\n",
      "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-58\" id=\"menu-item-58\"><a href=\"https://starbucksmenuprices.com/starbucks-canada-menu/\">Canada</a></li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "# Find all <ul> elements containing the country links\n",
    "sections = soup.find_all('ul')  # Locate all <ul> elements\n",
    "\n",
    "# Lists in Python: The result is a list, which can store multiple items.\n",
    "print(sections[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7_XXuejYaDE",
    "outputId": "6886139a-bd5d-4045-d4ac-6415987fdd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple banana cherry\n"
     ]
    }
   ],
   "source": [
    "# Example of List:\n",
    "my_list = ['apple', 'banana', 'cherry']\n",
    "print(my_list[0],my_list[1],my_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6kLrbMGZgXR"
   },
   "source": [
    "## **Step 6: Extract Links**\n",
    "Now, loop through each < ul > section to find < a > tags (anchors), which represent links.\n",
    "\n",
    "*   **link.text.strip()**: Extracts the text (e.g., \"Australia\") and removes extra spaces.\n",
    "*  **link.get('href')**: Retrieves the URL linked to the < a > tag.\n",
    "*  **country_links.append({...})**: Adds a dictionary with country name and URL to the list.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6lTXhJVY5jf"
   },
   "outputs": [],
   "source": [
    "# Extract links from the <ul> sections\n",
    "country_links = []  # Empty list to store results\n",
    "\n",
    "for section in sections:\n",
    "    links = section.find_all('a')  # Find all <a> tags in each section\n",
    "    for link in links:\n",
    "        country_name = link.text.strip()  # Get the visible text of the link\n",
    "        country_url = link.get('href')  # Get the href attribute (URL)\n",
    "        country_links.append({'Country': country_name, 'URL': country_url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7Y1LNOMZ4Cz",
    "outputId": "cfde1e36-cc55-4414-b074-9acfb2c84580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n",
      "cherry\n"
     ]
    }
   ],
   "source": [
    "# Example of Loop:\n",
    "for fruit in ['apple', 'banana', 'cherry']:\n",
    "    print(fruit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZwR1BEIaEMR"
   },
   "source": [
    "## **Step 7: Store Results in a DataFrame**\n",
    "DataFrames are tables provided by the **pandas** library, making it easy to organize and analyze data.\n",
    "*   **pd.DataFrame()**: Converts a list of dictionaries into a tabular format.\n",
    "*   **df.head()**: Displays the first 5 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sagggYqvaAjJ",
    "outputId": "539a2170-5552-463f-effd-e0d00c300f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Country                                                URL\n",
      "0        A-C                                                  #\n",
      "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
      "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
      "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
      "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for working with data\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df = pd.DataFrame(country_links)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ9B3yLXaYzv"
   },
   "source": [
    "## **Step 8: Save Results to a CSV File**\n",
    "Finally, save the data to a CSV file, which can be opened in Excel or analyzed further.\n",
    "*   **to_csv()**: Exports the DataFrame to a file.\n",
    "*   **index=False**: Prevents saving row numbers in the CSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMcQbPTHaRzf",
    "outputId": "b78cbd9d-97cc-4e0b-b15d-eda4e60692e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved country links to starbucks_country_links.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('starbucks_country_links.csv', index=False)\n",
    "print(\"Saved country links to starbucks_country_links.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWH-gjY-anPT"
   },
   "source": [
    "## **Complete Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTBOre91akMU",
    "outputId": "8df09c4e-0447-4e85-b027-d8f62e2dc631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage!\n",
      "     Country                                                URL\n",
      "0        A-C                                                  #\n",
      "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
      "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
      "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
      "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n",
      "Saved country links to starbucks_country_links.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Fetch the webpage content\n",
    "url = 'https://starbucksmenuprices.com/'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the webpage!\")\n",
    "else:\n",
    "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "\n",
    "# Step 2: Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Find all <ul> elements\n",
    "sections = soup.find_all('ul')\n",
    "\n",
    "# Step 4: Extract links\n",
    "country_links = []\n",
    "for section in sections:\n",
    "    links = section.find_all('a')\n",
    "    for link in links:\n",
    "        country_name = link.text.strip()\n",
    "        country_url = link.get('href')\n",
    "        country_links.append({'Country': country_name, 'URL': country_url})\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "df = pd.DataFrame(country_links)\n",
    "print(df.head())  # Display the first 5 rows\n",
    "\n",
    "# Step 6: Save to CSV\n",
    "df.to_csv('starbucks_country_links.csv', index=False)\n",
    "print(\"Saved country links to starbucks_country_links.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LMQgctXbC45"
   },
   "source": [
    "# **Extracting Starbucks Prices Data**\n",
    "### Example of scraping hot coffee price data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeWIMqaAbuPm"
   },
   "source": [
    "## **Step 1: Load the Links**\n",
    "*   **pd.read_csv()**: Reads the CSV file containing country links into a DataFrame.\n",
    "*   **links_file**: The file path of the CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34R8JoI8bJuf"
   },
   "outputs": [],
   "source": [
    "links_file = 'starbucks_country_links.csv'  # File containing country links\n",
    "country_links = pd.read_csv(links_file)  # Read the CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LVG-1Xub9Iw"
   },
   "source": [
    "## **Step 2: Filter Valid Links**\n",
    "*   **Filter Rows**: ~country_links['URL'].str.contains('#', na=False) excludes rows where the URL contains #.\n",
    "*   **iloc[0]**: Selects the first valid row.\n",
    "*   **Format Country Name**: Converts the country name to lowercase and replaces spaces with hyphens for file naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC_gy_nkb8JJ"
   },
   "outputs": [],
   "source": [
    "valid_links = country_links[~country_links['URL'].str.contains('#', na=False)]  # Filter rows without '#'\n",
    "if valid_links.empty:\n",
    "    print(\"No valid links found in the file.\")\n",
    "    exit()\n",
    "\n",
    "first_link = valid_links.iloc[0]  # Select the first valid row\n",
    "country_url = first_link['URL']  # Extract the URL from the first valid row\n",
    "country_name = first_link['Country'].lower().replace(' ', '-')  # Extract and format the country name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtc5vnQ_cknT"
   },
   "source": [
    "## **Step 3: Fetch the Webpage**\n",
    "*   **requests.get(url)**: Fetches the HTML content of the URL.\n",
    "*   **Check Status Code**: Ensures the webpage was successfully fetched (200 status code).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwYfH5dAb3Cv",
    "outputId": "dbb1dcf2-dbdd-4e91-fbba-4bb691d87347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the page: https://starbucksmenuprices.com/starbucks-au-prices/\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(country_url)\n",
    "if response.status_code == 200:\n",
    "    print(f\"Successfully fetched the page: {country_url}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0DrR1tjdnZo"
   },
   "source": [
    "## **Step 4: Parse the HTML**\n",
    "*   **BeautifulSoup(..., 'html.parser')**: Parses the HTML content into a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7NWyL2McptM"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeGYq65neXz_"
   },
   "source": [
    "## **Step 5: Locate \"h2\" Section**\n",
    "*   **Find < h2 > Heading**: Searches for the \"h2\" heading.\n",
    "*   **Find Parent Table**: If the heading is found, locate the parent table containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2w5i8SDpeTqS"
   },
   "outputs": [],
   "source": [
    "hot_coffee_heading = soup.find('h2')  # Locate the \"h2\" section heading\n",
    "if hot_coffee_heading:\n",
    "    hot_coffee_table = hot_coffee_heading.find_parent('table')  # Find the parent table containing the data\n",
    "else:\n",
    "    print(\"'Hot Coffee' section not found on the page.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS9viHetekWf"
   },
   "source": [
    "## **Step 6: Extract Data**\n",
    "*   **Find Rows**: Selects rows with class item.\n",
    "*  **Extract Columns**: Extracts text from each column and cleans it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I75UQkcxegiq"
   },
   "outputs": [],
   "source": [
    "hot_coffee_data = []  # List to store extracted data\n",
    "if hot_coffee_table:\n",
    "    rows = hot_coffee_table.find_all('tr', class_='item')  # Find all rows with class \"item\"\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')  # Find all columns in the row\n",
    "        cols = [col.string.strip() for col in cols]  # Clean the text\n",
    "        if cols:  # Skip empty rows\n",
    "            hot_coffee_data.append(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44TUK1Lsg2TA"
   },
   "source": [
    "## **Step 7: Save Data**\n",
    "*   **Dynamic File Name**: Includes the country name in the file name.\n",
    "*  **Save to CSV**: Exports the data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RZD09uUetEr",
    "outputId": "4ef5f214-595c-4b12-f1a2-8be47482c132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'Hot Coffee' prices to hot_coffee_prices_australia.csv\n",
      "                              Item  Price\n",
      "0                     Banana Bread  $6.30\n",
      "1                 Butter Croissant  $5.78\n",
      "2                 Almond Croissant  $5.78\n",
      "3                Pain Au Chocolate  $5.50\n",
      "4                 Pain Au Chocolat  $6.00\n",
      "..                             ...    ...\n",
      "74               Caramel Macchiato  $6.88\n",
      "75           White Chocolate Mocha  $6.16\n",
      "76                     Caffé Mocha  $6.35\n",
      "77         Caramel Cloud Macchiato  $8.00\n",
      "78  Honeycomb Salted Caramel Latte  $7.30\n",
      "\n",
      "[79 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "if hot_coffee_data:\n",
    "    df_hot_coffee = pd.DataFrame(hot_coffee_data, columns=['Item', 'Price'])  # Create a DataFrame\n",
    "    output_file = f'hot_coffee_prices_{country_name}.csv'  # Generate file name with country name\n",
    "    df_hot_coffee.to_csv(output_file, index=False)  # Save to CSV\n",
    "    print(f\"Saved 'Hot Coffee' prices to {output_file}\")\n",
    "    print(df_hot_coffee)  # Print the result\n",
    "else:\n",
    "    print(\"No 'Hot Coffee' data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QU5qaet1g9kG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f1d6fe",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis of Findings\n",
    "\n",
    "## Comparison of Actual Exchange Rates and PPP Rates\n",
    "\n",
    "The analysis reveals significant deviations between the actual exchange rates and the PPP rates calculated from Starbucks Latte prices. For instance, in Australia, the implied PPP rate based on Starbucks prices is 1.53 AUD per USD, which is approximately 138.89% higher than the actual exchange rate of 0.64 AUD per USD. This substantial deviation suggests that the Australian Dollar is undervalued in the actual exchange rates compared to what the Starbucks Latte Index implies.\n",
    "\n",
    "## Starbucks Latte Index vs. Big Mac Index\n",
    "\n",
    "The Starbucks Latte Index provides a contemporary measure of purchasing power, showing significant discrepancies when compared to actual exchange rates. Unlike the Big Mac Index, which might incorporate a variety of economic factors, the Starbucks Latte Index might be influenced more by local pricing strategies and cost structures specific to the coffee industry.\n",
    "\n",
    "### Implications\n",
    "\n",
    "These findings suggest that while traditional PPP calculations like the Big Mac Index provide a broad view of the economic standings, niche indices like the Starbucks Latte Index can reveal localized economic behaviors that differ significantly. The variations in index results may also reflect distinct consumer behavior patterns or business operating costs across different markets.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "56tfDxbWVq9b"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
